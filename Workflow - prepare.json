{"paragraphs":[{"user":"anonymous","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"editOnDblClick":false,"language":"text"},"editorMode":"ace/mode/text","title":true,"tableHide":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1509040775770_-146782159","id":"20171026-175935_775290633","dateCreated":"2017-10-26T17:59:35+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:6983","text":"%jdbc(hive)\nDROP TABLE IF EXISTS ratings_partitioned;\nCREATE EXTERNAL TABLE IF NOT EXISTS ratings_partitioned\n(\n UserID            int,\n  MovieID           int,\n  Rating            double,\n  Time_stamp         timestamp\n)\nPARTITIONED BY (year int)\nROW FORMAT DELIMITED\nFIELDS TERMINATED BY '|'\nSTORED AS TEXTFILE\nLOCATION '/data/external-tables/ratings_partitioned';","dateUpdated":"2017-10-26T19:19:40+0000","dateFinished":"2017-10-26T18:25:39+0000","dateStarted":"2017-10-26T18:25:38+0000","title":"1 - Create partitioned table with TEXT format - just to export data to local machine","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Query executed successfully. Affected rows : -1"},{"type":"TEXT","data":"Query executed successfully. Affected rows : -1"}]}},{"user":"anonymous","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"editOnDblClick":false,"language":"sh"},"editorMode":"ace/mode/sh","title":true,"tableHide":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1509040925658_999767919","id":"20171026-180205_1130716218","dateCreated":"2017-10-26T18:02:05+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:7081","text":"%sh\nhdfs dfs -get /data/external-tables/ratings_partitioned /tmp/","dateUpdated":"2017-10-26T19:19:37+0000","dateFinished":"2017-10-26T18:25:48+0000","dateStarted":"2017-10-26T18:25:41+0000","title":"2 - Export data to local machine","results":{"code":"SUCCESS","msg":[]}},{"text":"%sh\nhdfs dfs -rm -r -f -skipTrash /data/input/input_ratings\nhdfs dfs -rm -r -f -skipTrash /data/output/target_table","user":"anonymous","dateUpdated":"2017-10-26T19:19:34+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"editOnDblClick":false,"language":"sh"},"editorMode":"ace/mode/sh","title":true,"tableHide":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1509041126513_700108178","id":"20171026-180526_960628901","dateCreated":"2017-10-26T18:05:26+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:7212","dateFinished":"2017-10-26T18:26:30+0000","dateStarted":"2017-10-26T18:26:26+0000","title":"3 - Clear directories from previous runs","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Deleted /data/input/input_ratings\nDeleted /data/output/target_table\n"}]}},{"text":"%jdbc(hive)\n\nDROP TABLE IF EXISTS input_ratings;\nCREATE EXTERNAL TABLE IF NOT EXISTS input_ratings\n(\n UserID            int,\n  MovieID           int,\n  Rating            double,\n  Time_stamp         timestamp\n)\nPARTITIONED BY (year int)\nROW FORMAT DELIMITED\nFIELDS TERMINATED BY '|'\nSTORED AS TEXTFILE\nLOCATION '/data/input/input_ratings';\n\nDROP TABLE IF EXISTS target_table;\nCREATE EXTERNAL TABLE IF NOT EXISTS target_table\n(\n  UserID            int,\n  MovieID           int,\n  Title             string,\n  Genres            string,\n  Rating            double,\n  Time_stamp         timestamp\n)\nPARTITIONED BY (year int)\nSTORED AS ORC\nLOCATION '/data/output/target_table';\n","user":"anonymous","dateUpdated":"2017-10-26T19:19:36+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"editOnDblClick":false,"language":"text"},"editorMode":"ace/mode/text","title":true,"tableHide":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1509041018746_-88363268","id":"20171026-180338_2140861818","dateCreated":"2017-10-26T18:03:38+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:7156","dateFinished":"2017-10-26T18:27:22+0000","dateStarted":"2017-10-26T18:27:20+0000","title":"4 - Create input and output tables","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Query executed successfully. Affected rows : -1"},{"type":"TEXT","data":"Query executed successfully. Affected rows : -1"},{"type":"TEXT","data":"Query executed successfully. Affected rows : -1"},{"type":"TEXT","data":"Query executed successfully. Affected rows : -1"}]}},{"user":"anonymous","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"editOnDblClick":false,"language":"sh"},"editorMode":"ace/mode/sh","title":true,"tableHide":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1509042093087_832845427","id":"20171026-182133_100659789","dateCreated":"2017-10-26T18:21:33+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:7314","text":"%sh\ngit clone https://github.com/elisska/wf-hive-example\nhdfs dfs -mkdir -p /data/oozie-jobs\nhdfs dfs -put -f wf-hive-example /data/oozie-jobs/","dateUpdated":"2017-10-26T19:19:45+0000","dateFinished":"2017-10-26T18:27:34+0000","dateStarted":"2017-10-26T18:27:26+0000","title":"5 - Copy Oozie workflow code and put it to HDFS","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Initialized empty Git repository in /home/zeppelin/wf-hive-example/.git/\n"}]}},{"text":"%sh\noozie job -oozie http://localhost:11000/oozie -run -config wf-hive-example/job.properties","user":"anonymous","dateUpdated":"2017-10-26T18:29:09+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"editOnDblClick":false,"language":"sh"},"editorMode":"ace/mode/sh","title":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1509042446261_30144851","id":"20171026-182726_208441326","dateCreated":"2017-10-26T18:27:26+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:7642","dateFinished":"2017-10-26T18:29:11+0000","dateStarted":"2017-10-26T18:29:09+0000","title":"6 - Start Oozie coordinator job","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"job: 0000034-171025231324315-oozie-oozi-C\n"}]}},{"text":"%sh\nYEARS=`ls -1 /tmp/ratings_partitioned/ | cut -d\"=\" -f2`\nfor i in $YEARS \ndo \n  hdfs dfs -put -f /tmp/ratings_partitioned/year\\=$i/ /data/input/input_ratings/$i\n  echo \"Year $i copied to hdfs\"\n  sleep 60\ndone;","user":"anonymous","dateUpdated":"2017-10-26T19:19:29+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"editOnDblClick":false,"language":"sh"},"editorMode":"ace/mode/sh","title":true,"tableHide":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1509043045878_-284690308","id":"20171026-183725_1474857148","dateCreated":"2017-10-26T18:37:25+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:7876","dateFinished":"2017-10-26T18:46:39+0000","dateStarted":"2017-10-26T18:43:35+0000","title":"7 - Start copying data to HDFS - BETTER TO RUN FROM COMMAND LINE DIRECTLY TO AVOID SIGTERM","results":{"code":"INCOMPLETE","msg":[{"type":"TEXT","data":"Paragraph received a SIGTERM\nExitValue: 143"}]}},{"text":"%jdbc(hive)\nselect year, count(*) as cnt \nfrom target_table\ngroup by year;\n","user":"anonymous","dateUpdated":"2017-10-26T19:19:25+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"editOnDblClick":false,"language":"text"},"editorMode":"ace/mode/text","title":true,"tableHide":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1509043142881_-1382224034","id":"20171026-183902_1668514352","dateCreated":"2017-10-26T18:39:02+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:8036","dateFinished":"2017-10-26T19:08:22+0000","dateStarted":"2017-10-26T19:06:59+0000","title":"8 - Verify that data appears in target table","results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"year\tcnt\n1995\t4\n1996\t1612609\n"}]}},{"user":"anonymous","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"editOnDblClick":false,"language":"sql"},"editorMode":"ace/mode/sql"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1509043240776_-826757180","id":"20171026-184040_9316349","dateCreated":"2017-10-26T18:40:40+0000","status":"READY","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:8116"}],"name":"Workflow - prepare","id":"2CYGADMP7","angularObjects":{"2CND78TZ5:shared_process":[],"2CR2V48XX:shared_process":[],"2CR42WHB9:shared_process":[],"2CS1CKTB6:shared_process":[],"2C8A4SZ9T_livy2:shared_process":[],"2CR8B4RNG:shared_process":[],"2A4U48MY3_spark2:shared_process":[],"2CQR2Q67N:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}